{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e96eb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raashidkhan/Desktop/GitHub-Projects/MNIST_Classification/notebook /opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python313.zip\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('/Users/raashidkhan/Desktop/GitHub-Projects/MNIST_Classification')\n",
    "print(os.getcwd(), sys.path[0])\n",
    "from src.training import load_split, get_or_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5165ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=load_split()\n",
    "model = get_or_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b29f2c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted  Actual\n",
       "0          False   False\n",
       "1          False   False\n",
       "2          False   False\n",
       "3          False   False\n",
       "4          False   False\n",
       "...          ...     ...\n",
       "59995      False   False\n",
       "59996       True    True\n",
       "59997      False   False\n",
       "59998      False   False\n",
       "59999      False   False\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predictions = model.predict(X_train)\n",
    "import pandas as pd\n",
    "pd.DataFrame({'Predicted': predictions, 'Actual': y_train==5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81cd9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 5\n"
     ]
    }
   ],
   "source": [
    "print (predictions[10], y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5c68cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53338,  1242],\n",
       "       [  922,  4498]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train==5, y_train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07c8c1",
   "metadata": {},
   "source": [
    "True Negatives=53338\n",
    "True Positives=4498\n",
    "False Negative=922\n",
    "False Positive=1242"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991916f9",
   "metadata": {},
   "source": [
    "Now let us say we reached perfection by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16260d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54580,     0],\n",
       "       [    0,  5420]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_predictions = y_train==5\n",
    "confusion_matrix(y_train==5, perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad21ee",
   "metadata": {},
   "source": [
    "So, there have been false negatives and false positives in our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59685afd",
   "metadata": {},
   "source": [
    "Now, to know exact accuracy/performance of our model, we need to consider these things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbeff3",
   "metadata": {},
   "source": [
    "precision = TP/TP + FP\n",
    "recall = TP/TP + FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58f48b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.783623693379791\n",
      "Recall Score:  0.8298892988929889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print ('Precision Score: ',precision_score(y_train==5, y_train_predictions))\n",
    "print ('Recall Score: ',recall_score(y_train==5, y_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3996cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Score:  0.783623693379791\n",
    "#Recall Score:  0.8298892988929889"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dcd21",
   "metadata": {},
   "source": [
    "Now, our model doesnt look as good as it was using cross_val_score\n",
    "Now, we get why should we use confusion matrix to calculate performance of binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424f9e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
